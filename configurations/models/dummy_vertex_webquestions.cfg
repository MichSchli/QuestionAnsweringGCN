[architecture]
    model_type = none
    inverse_relations = separate
    final_sentence_embedding = sentence_attention
    add_deplambda = True

[gcn]
    layers = 1
    embedding_dimension = 200
    message_hidden_dimension = 200
    gate_hidden_dimension = 200

[lstm]
    layers = 2
    embedding_dimension = 200
    attention_heads = 1
    static_word_embeddings = True

[other]
    final_hidden_dimensions = 400

[regularization]
    word_dropout = 0.0
    final_l2 = 0.001
    final_dropout = 0.2
    attention_dropout = 0.2
    gate_l1 = 0.0001
    gcn_dropout = 0.2
    gcn_l2 = 0.001

[endpoint]
    type = sparql
    prefix = http://rdf.freebase.com/ns/
    disk_cache = /datastore/michael_cache/webquestions.1neighbors.cache
    facts = freebase
    project_names = True

[dataset]
    train_file = data/webquestions/valid.split.uppercased_and_tagged.conll
    valid_file = data/webquestions/valid.split.uppercased_and_tagged.conll
    test_file = data/webquestions/valid.split.uppercased_and_tagged.conll
    transform_mention_scores = log
    deplambda_train_file = data/webquestions/siva.train.split.deplambda.conll
    deplambda_valid_file = data/webquestions/siva.valid.split.deplambda.conll
    deplambda_test_file = data/webquestions/siva.valid.split.deplambda.conll

[indexes]
    relation_index_type = freebase_limited:100
    vertex_index_type = freebase_default_vertices:100
    word_index_type = dep:300
    pos_index_type = default_pos:10
    relation_part_index_type = freebase_default_relation_part:10

[training]
    subsampling = 500
    batch_size = 5
    max_iterations = 100
    validate_every_n = 1
    report_loss_every_n = 10
    early_stopping = False
    filter_gold_labels = maximize_f1
    learning_rate = 0.001
    gradient_clipping = 1.0

[testing]
    batch_size = 1