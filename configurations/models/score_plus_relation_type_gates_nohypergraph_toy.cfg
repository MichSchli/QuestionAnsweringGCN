[model]
    stack_name = lstm+score_gcn_gates_nohypergraph
    use_transformation = True
    word_embedding_type = none
    entity_embedding_type = none
    entity_embedding_dimension = 100
    word_embedding_dimension = 100
    lstm_hidden_state_dimension = 200
    n_attention_heads = 2
    nn_hidden_state_dimension = 400
    n_lstms=2
    n_layers=4
    regularization_scale=0.0001
    scoring_function=neural_network
    attention_dropout=0.1
    word_dropout=0.1
    transform_dropout=0.1
    edge_dropout=0.0
    static_word_embeddings = True
    concatenate_scores = True
    loss = weighted_sigmoid
    relation_part_embedding_type = lazy_part_indexer
    relation_part_embedding_dimension = 10
    relation_embedding_dimension = 20
    gate_regularization = 0.001
    layer_reuse = 1

[training]
    max_epochs = 200
    early_stopping = False
    epochs_between_tests = 1
    search = grid
    batch_size = 5
    test_batch_size = 1
    learning_rate = 0.001
    gradient_clipping = 1
    average_loss_over_n = 5
    split_graph = False
    propagate_scores = True
    subsampling = None
    gold_labels = maximize_f1

[endpoint]
    type = csv
    file = data/toy-125/toy.graph
    disk_cache = data/toy-125/1neighbors.cache
    facts = toy

[dataset]
    train_file = data/toy-125/train.internal.uppercased_and_tagged.conll
    valid_file = data/toy-125/test.internal.uppercased_and_tagged.conll
    test_file = data/toy-125/test.internal.uppercased_and_tagged.conll

[evaluation]
    type = cutoff
    cutoff = 0.5
    method = macro

[other]
    disambiguation = False
    transform_disambiguation_scores = None
