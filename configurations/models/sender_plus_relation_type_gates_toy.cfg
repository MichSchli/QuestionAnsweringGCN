[model]
    stack_name = lstm+sender_gcn_gates
    use_transformation = True
    word_embedding_type = none
    entity_embedding_type = none
    entity_embedding_dimension = 100
    word_embedding_dimension = 100
    lstm_hidden_state_dimension = 200
    n_attention_heads = 1
    nn_hidden_state_dimension = 400
    n_lstms=1
    n_layers=1,2
    regularization_scale=0.001
    scoring_function=neural_network
    attention_dropout=0.1
    word_dropout=0.0
    transform_dropout=0.1
    edge_dropout=0.0
    static_word_embeddings = True
    concatenate_scores = True
    loss = weighted_sigmoid

[training]
    max_epochs = 30
    early_stopping = False
    epochs_between_tests = 1
    search = grid
    batch_size = 5
    learning_rate = 0.001
    gradient_clipping = 1
    average_loss_over_n = 5
    split_graph = False
    propagate_scores = True
    subsampling = 5
    gold_labels = maximize_f1

[endpoint]
    type = csv
    file = data/toy-125/toy.graph
    disk_cache = data/toy-125/1neighbors.cache
    facts = toy

[dataset]
    train_file = data/toy-125/train.internal.conll
    valid_file = data/toy-125/test.internal.conll
    test_file = data/toy-125/test.internal.conll

[evaluation]
    type = cutoff
    cutoff = 0.5
    method = macro

[other]
    disambiguation = False
    transform_disambiguation_scores = None
