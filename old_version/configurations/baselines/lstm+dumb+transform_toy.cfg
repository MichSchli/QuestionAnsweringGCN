[model]
    stack_name = lstm+dumb
    use_transformation = True
    word_embedding_type = none
    entity_embedding_type = none
    entity_embedding_dimension = 50,100,200
    word_embedding_dimension = 50,100,200
    n_lstms = 1,2,3
    regularization_scale=0.0,0.001,0.01,0.1,1.0

[training]
    max_epochs = 100
    early_stopping = True
    epochs_between_tests = 1
    search = greedy
    batch_size = 10,20,50,100,200
    learning_rate = 0.01, 0.001, 0.0001

[endpoint]
    type = csv
    file = data/toy-125/toy.graph
    disk_cache = data/toy-125/1neighbors.cache
    facts = toy

[dataset]
    train_file = data/toy-125/train.internal.conll
    valid_file = data/toy-125/test.internal.conll
    test_file = data/toy-125/test.internal.conll